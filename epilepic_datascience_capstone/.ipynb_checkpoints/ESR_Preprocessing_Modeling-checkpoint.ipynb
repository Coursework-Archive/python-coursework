{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epileptic = pd.read_csv(\"Epileptic Seizure Recognition.csv\")\n",
    "epileptic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = epileptic[.drop(columns='y')\n",
    "y = epileptic.y\n",
    "\n",
    "\n",
    "#Split data into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN/DNN/??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBSCAN: Density-Based Spatial Clustering of Applications with Noise\n",
    "\n",
    "Unsupervised learning method that separates the data points into several specific bunches or groups, such that the data points in the same groups have similar properties and data points in different groups have different properties in some sense.\n",
    "\n",
    "It is comprised of many different methods based on different distance measures. E.g. K-Means (Euclidean distance between points), DBSCAN (distance between nearest points, Gaussian mixtures (Mahalanobis distance to centers), Spectral clustering (graph distance) etc.\n",
    "\n",
    "The DBSCAN algorithm uses two parameters:\n",
    "\n",
    "* minPts: The minimum number of points (a threshold) clustered together for a region to be considered dense. As a rule of thumb, a minimum minPts can be derived from the number of dimensions D in the the data set, as minPts >= D + 1. Therefore, minPts must be chosen at least 3. However, larger values are usually better for data sets with noiise and will yeild more significant clusters. As a rule of thumb, minPts = 2 * dim can be used, but ut may be necessary to choose larger values for vry loarge data, for noisy data as for data or for data that contains many duplicates \n",
    "\n",
    "* eps ( $ \\epselon $ ): A distance measure that will be used to locate the points in the neighborhood of any points. The value of $\\epselon$ can then be chosen by using a k-distance graph, plotting the distance to the k=minPts-1 nearest neighbor ordered from the largest to the smallst value. Good values of the $\\epselon$ are where this plot shows an \"elbow\": if $\\epselon$ is chosen much too small, a large part of the data will not be clustered; whereas for a too high values of $\\epselon$, clusters will merge and the majority of objects will be the same cluster. In general, small values of $\\epselon$ are preferable, and as a rule of thumb, only a small fraction of points should be within this distance of each other. \n",
    "\n",
    "* Distance function:  The choice of distance function is tightly linked to the choice of $\\epselon$, and has a major impact on the outcomes. In general, it will be necessary to the first identify a reasonable measure of similarity for the dataset, before the parameter $\\epselon$ can be chosen. there is no estimation for this parameter, but the distance functions need to be chosen appropriately for the data set. \n",
    "These parameters can be understood if we explore two concepts called density Reachable Density and Density Connectivity.\n",
    "\n",
    "##Reachability## in terms of density establishes a point to be reachable from another if it lies within a particular distance (eps) from it.\n",
    "\n",
    "##Connectivity##, on the other hand, involves a transitivity based chaining-approach to determine whether points are located in a particular cluster. For example, p and q points could be connected if p->r->s->t->q, where a->b means b is the neighborhood of a.\n",
    "\n",
    "There three types of points after the DBSCAN clustering is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine eps using KNN\n",
    "def knn_accuracy(X, X_, y, y_):\n",
    "    \n",
    "    test_scores = []\n",
    "    train_scores = []\n",
    "\n",
    "    for i in range(1,10):\n",
    "\n",
    "        knn = KNeighborsClassifier(i, n_jobs=-1)\n",
    "        knn.fit(X,y)\n",
    "        y_pred = knn.predict(X_)\n",
    "    \n",
    "        train_scores.append(knn.score(X,y))\n",
    "        test_scores.append(knn.score(y_pred, y_))\n",
    "\n",
    "    train = [round(i, 4) for i in train_scores]\n",
    "    test = [round(ii, 4) for ii in test_scores]\n",
    "    \n",
    "    \n",
    "#     train_index = train_scores.index(max(train_scores))+1\n",
    "    best_neighbors = test_scores.index(max(test_scores))+1\n",
    "    best_index = test_scores.index(max(test_scores))\n",
    "                           \n",
    "    plt.figure(figsize=(12,5))\n",
    "    p = sns.lineplot(range(1,10),train_scores,marker='*',label='Train Score')\n",
    "    p = sns.lineplot(range(1,10),test_scores,marker='o',label='Test Score')\n",
    "    \n",
    "    print(\"Train Accuracy: \", train[best_index])\n",
    "    print(\"Best Neighbors: \", best_neighbors)\n",
    "    print(\"Test Accuracy: \", test[best_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute DBSCAN\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X_train)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "#Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)\n",
    "print('Estimated number of noise points: %d' % n_noise_)\n",
    "print('Homogeneity: %0.3f' % metrics.homogeneity_score(y_train, labels))\n",
    "print('Completeness: %0.3f' % metrics.v_measure_score(y_train, labels))\n",
    "print('V-measure: %0.3f' % metrics.v_measure_score(y_train, labels))\n",
    "print('Adjusted Rand Index: %0.3f' % metrics.adjusted_rand_score(y_train, labels))\n",
    "print('Adjusted Mutual Information: %0.3f' % metrics.adjusted_mutual_info_score(y_train, labels))\n",
    "print('Silhouette Coefficient: %0.3f' % metrics.silhouette_score(X_train, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot result\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Black removed and is used for noise instead.\n",
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
