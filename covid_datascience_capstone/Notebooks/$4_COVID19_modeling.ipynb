{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A big part of time series analysis involves filtering - i.e. changing attributes of a time series or deconstructing it into its component parts. Often we need to do quite a bit of time series before we build a model to simulate the underlying process.\n",
    "\n",
    "\n",
    "To run the ADF test we need to chose a lag length so that the residuals aren't serially correlated (aka Autocorrelation), this is to minimize error terms in a time series as to avoid transferring them from one period to another. For choosing the lags the AIC (Akaike's information criterion) will be minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The behavior of time series models, the constant c has an important effect on the long-long term forecasts obtained from these models. \n",
    "\n",
    "    - If c = 0 and d = , the long-term forecase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After graphing the difference for a stationary model determining ARMA, AR or MA \n",
    "\n",
    "The special cases of ARIMA models \n",
    "\n",
    "    White noise             ARIMA(0,0,0)\n",
    "    Random walk             ARIMA(0,1,0) with no constant \n",
    "    Random walk with drift  ARIMA(0,1,0) with a constant\n",
    "    Autoregression          ARIMA(p,0,0)\n",
    "    Moving average          ARIMA(0,0,q)\n",
    "\n",
    "ACF and PACF cannot be used to choose the order of a model when both the orders q and p are non-zero. Instead there are other models the AIC and BIC.\n",
    "\n",
    "    a. The model with the lower AIC Score makes better predictions \n",
    "    \n",
    "\n",
    "If you receive a value error this is a bad model for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files\n",
    "pbc_afa = pd.read_csv('../data/pre_bc_afa.csv', index_col=0)\n",
    "pbc_afr = pd.read_csv('../data/pre_bc_afr.csv', index_col=0)\n",
    "pbc_asr = pd.read_csv('../data/pre_bc_asr.csv', index_col=0)\n",
    "pbc_asa = pd.read_csv('../data/pre_bc_asa.csv', index_col=0)\n",
    "pbc_ea = pd.read_csv('../data/pre_bc_ea.csv', index_col=0)\n",
    "pbc_er = pd.read_csv('../data/pre_bc_er.csv', index_col=0)\n",
    "pbc_nr = pd.read_csv('../data/pre_bc_nr.csv', index_col=0)\n",
    "pbc_na = pd.read_csv('../data/pre_bc_na.csv', index_col=0)\n",
    "pbc_sr = pd.read_csv('../data/pre_bc_sr.csv', index_col=0)\n",
    "pbc_sa = pd.read_csv('../data/pre_bc_sa.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the models\n",
    "import warnings\n",
    "afa = pickle.load(open('../models/af_act_model.sav', 'rb'))\n",
    "afr = pickle.load(open('../models/af_rec_model.sav', 'rb')) \n",
    "asa = pickle.load(open('../models/asia_act_model.sav', 'rb'))\n",
    "asr = pickle.load(open('../models/asia_rec_model.sav', 'rb')) \n",
    "ea = pickle.load(open('../models/eu_act_model.sav', 'rb')) \n",
    "er = pickle.load(open('../models/eu_rec_model.sav', 'rb')) \n",
    "na = pickle.load(open('../models/noam_act_model.sav', 'rb')) \n",
    "nr = pickle.load(open('../models/noam_rec_model.sav', 'rb'))\n",
    "sa = pickle.load(open('../models/soam_act_model.sav', 'rb')) \n",
    "sr = pickle.load(open('../models/soam_rec_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Africa Active Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_arima_model(data, arima_order):\n",
    "    # Needs to be an integer because it is later used as an index.\n",
    "    # Use int()\n",
    "    split=int(len(data) * 0.7) \n",
    "    # Make train and test variables, with 'train, test'\n",
    "    train, test = data[0:split], data[split:len(data)]\n",
    "    past=[x for x in train]\n",
    "    # make predictions. Declare a variable with that name\n",
    "    predictions = list()\n",
    "    for i in range(len(test)):#timestep-wise comparison between test data and one-step prediction ARIMA model. \n",
    "        past_bc, fitted_lambda = stats.boxcox(past)\n",
    "        test_bc = stats.boxcox(test, fitted_lambda)\n",
    "        model = ARIMA(past_bc, order=arima_order)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        future = model_fit.forecast()[0]\n",
    "        # Append() here\n",
    "        predictions.append(future)\n",
    "        past.append(test_bc[i])\n",
    "    # calculate out of sample error\n",
    "    error = mean_squared_error(test_bc, predictions)\n",
    "    # Return the error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = evaluate_arima_model(pbc_afa, 0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_arima_model(data, arima_order):\n",
    "#     # Needs to be an integer because it is later used as an index.\n",
    "#     # Use int()\n",
    "#     split=int(len(data) * 0.7) \n",
    "#     # Make train and test variables, with 'train, test'\n",
    "#     train, test = data[0:split], data[split:len(data)]\n",
    "#     past=[x for x in train]\n",
    "#     # make predictions. Declare a variable with that name\n",
    "#     predictions = list()\n",
    "#     for i in range(len(test)):#timestep-wise comparison between test data and one-step prediction ARIMA model. \n",
    "#         past_bc, fitted_lambda = stats.boxcox(past)\n",
    "#         test_bc = stats.boxcox(test, fitted_lambda)\n",
    "#         model = ARIMA(past_bc, order=arima_order)\n",
    "#         model_fit = model.fit(disp=0)\n",
    "#         future = model_fit.forecast()[0]\n",
    "#         # Append() here\n",
    "#         predictions.append(future)\n",
    "#         past.append(test_bc[i])\n",
    "        \n",
    "#         return past, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-02</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-03</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-04</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-05</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-06</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-27</th>\n",
       "      <td>26779.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>26182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>26446.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>24726.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>24301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             active\n",
       "date               \n",
       "2020-03-02      1.0\n",
       "2020-03-03      1.0\n",
       "2020-03-04      1.0\n",
       "2020-03-05      2.0\n",
       "2020-03-06      2.0\n",
       "...             ...\n",
       "2020-12-27  26779.0\n",
       "2020-12-28  26182.0\n",
       "2020-12-29  26446.0\n",
       "2020-12-30  24726.0\n",
       "2020-12-31  24301.0\n",
       "\n",
       "[305 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbc_afa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 1) (92, 1)\n"
     ]
    }
   ],
   "source": [
    "split=int(len(pbc_afa) * 0.7)\n",
    "train, test = pbc_afa[0:split], pbc_afa[split:len(pbc_afa)]\n",
    "print(train.shape, test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = train[train > 0].sum()\n",
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d5679b8537b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbc_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted_lambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboxcox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py\u001b[0m in \u001b[0;36mboxcox\u001b[1;34m(x, lmbda, alpha)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional."
     ]
    }
   ],
   "source": [
    "bc_train, fitted_lambda = stats.boxcox(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    past_bc, fitted_lambda = stats.boxcox(past)\n",
    "    test_bc = stats.boxcox(test, fitted_lambda)\n",
    "    model = ARIMA(past_bc, order=arima_order)\n",
    "    model_fit = model.fit(disp=0)\n",
    "    future = model_fit.forecast()[0]\n",
    "    # Append() here\n",
    "    predictions.append(future)\n",
    "    past.append(test_bc[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pbc_afa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past, predictions = evaluate_arima_model(pbc_afa, (0,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>ARMA Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>active</td>      <th>  No. Observations:  </th>    <td>305</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARMA(0, 0)</td>    <th>  Log Likelihood     </th> <td>-3371.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>css</td>       <th>  S.D. of innovations</th> <td>15277.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 09 Sep 2021</td> <th>  AIC                </th> <td>6746.358</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:36:27</td>     <th>  BIC                </th> <td>6753.798</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>           <td>03-02-2020</td>    <th>  HQIC               </th> <td>6749.334</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                 <td>- 12-31-2020</td>   <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.436e+04</td> <td>  874.761</td> <td>   16.417</td> <td> 0.000</td> <td> 1.26e+04</td> <td> 1.61e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              ARMA Model Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:                 active   No. Observations:                  305\n",
       "Model:                     ARMA(0, 0)   Log Likelihood               -3371.179\n",
       "Method:                           css   S.D. of innovations          15277.046\n",
       "Date:                Thu, 09 Sep 2021   AIC                           6746.358\n",
       "Time:                        11:36:27   BIC                           6753.798\n",
       "Sample:                    03-02-2020   HQIC                          6749.334\n",
       "                         - 12-31-2020                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.436e+04    874.761     16.417      0.000    1.26e+04    1.61e+04\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afa.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Africa Recover Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>ARMA Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>recovered</td>    <th>  No. Observations:  </th>     <td>294</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>            <td>ARMA(0, 0)</td>    <th>  Log Likelihood     </th>  <td>-3858.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>css</td>       <th>  S.D. of innovations</th> <td>121215.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Thu, 09 Sep 2021</td> <th>  AIC                </th>  <td>7721.066</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:36:30</td>     <th>  BIC                </th>  <td>7728.433</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sample:</th>           <td>03-13-2020</td>    <th>  HQIC               </th>  <td>7724.017</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                 <td>- 12-31-2020</td>   <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 9.118e+04</td> <td> 7069.421</td> <td>   12.897</td> <td> 0.000</td> <td> 7.73e+04</td> <td> 1.05e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                              ARMA Model Results                              \n",
       "==============================================================================\n",
       "Dep. Variable:              recovered   No. Observations:                  294\n",
       "Model:                     ARMA(0, 0)   Log Likelihood               -3858.533\n",
       "Method:                           css   S.D. of innovations         121215.320\n",
       "Date:                Thu, 09 Sep 2021   AIC                           7721.066\n",
       "Time:                        11:36:30   BIC                           7728.433\n",
       "Sample:                    03-13-2020   HQIC                          7724.017\n",
       "                         - 12-31-2020                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       9.118e+04   7069.421     12.897      0.000    7.73e+04    1.05e+05\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asia Active Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asa.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asia Recovered Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "asr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Europe Active Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ea.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Europe Recovery Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "North America Active Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "North America Recovery Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "South America Active Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "South America Recovery Summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitting start_params, residuals are obtained from an AR fit, then an ARMA(p,q) model is fit via OLS using these residuals. If start_ar_lags is None, fit an AR process according to best BIC. If start_ar_lags is not None, fits an AR process with a lag length equal to start_ar_lags. See ARMA._fit_start_params_hr for more information.\n",
    "\n",
    "AR models have theoretical PACFs with non-zero values at the AR terms in the model and zero values elsewhere. The ACF will taper to zero in some fashion.\n",
    "\n",
    "MA models have theoretical ACFs with non-zero values at the MA terms in the model and zero values elsewhere.  The PACF will taper to zero in some fashion.\n",
    "\n",
    "If the series autocorrelations are non-significant, then the series is random (white noise; the ordering matters, but the data are independent and identically distributed.) Youâ€™re done at that point.\n",
    "\n",
    "If first differences were necessary and all the differenced autocorrelations are non-significant, then the original series is called a random walk and you are done. (A possible model for a random walk is $ x_t = \\delta + x_{t-1} + w_t $ . The data are dependent and are not identically distributed; in fact both the mean and variance are increasing through time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(data, model):\n",
    "    # Split data\n",
    "    split=int(len(data) * 0.7) \n",
    "    # Make train and test variables, train, test\n",
    "    train, test = data[0:split], data[split:len(data)]\n",
    "    # Fit the data to the model      \n",
    "    model_fit = model.fit()\n",
    "    # Forecast the data \n",
    "    forecast = model_fit.forecast(24)\n",
    "    \n",
    "    return forecast, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Africa, Asia.recovered ARIMA(0,0,0) white noise\n",
    "# Africa Recovered BIC = 7728.433\n",
    "# Africa Active BIC = 6753.798\n",
    "# Asia Recovered BIC = 11626.831\n",
    "a_a_models = [asr, afa, afr]\n",
    "a_a_sample_data = [pbc_afa, pbc_afr, pbc_asr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asia active, South America Recovered, ARIMA(0,0,1)\n",
    "# Asia Active BIC = 9692.586\n",
    "# South America Active BIC = \n",
    "# South America Recovered BIC =\n",
    "# The PACF will taper to zero in some fashion.\n",
    "\n",
    "a_r_models = [asa, sr]\n",
    "a_r_samples_data = [pbc_asa, pbc_sr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Europe recovered ARIMA(2,0,0)\n",
    "# Fit two lag start length\n",
    "# An AR(2) has two spikes in the PACF and a sinusoidal ACF that converges to 0.\n",
    "er\n",
    "pbc_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Europe active, North America, South America Active ARIMA(1,0,0)\n",
    "# Fit one lag start length\n",
    "# An AR(1) model has a single spike in the PACF and an ACF with a pattern\n",
    "n_s_e_models = [na, nr, sa, ea]\n",
    "sample_data = [pbc_ea, pbc_nr, pbc_na, pbc_sa] \n",
    "\n",
    "\n",
    "for i in sample_data: \n",
    "    train, test = split_data(i)\n",
    "    for ii in model_list:\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#North America Active \n",
    "na_pred = pd.DataFrame(na.predict(), columns=['active'])\n",
    "\n",
    "#North America Recovered\n",
    "nr_pred = pd.DataFrame(nr.predict(), columns=['recovered'])\n",
    "\n",
    "#South America Active\n",
    "sa_pred = pd.DataFrame(sa.predict(), columns=['active'])\n",
    "\n",
    "#South America Recovered\n",
    "sr_pred = pd.DataFrame(sr.predict(), columns=['recovered'])\n",
    "\n",
    "#Europe Active\n",
    "ea_pred = pd.DataFrame(ea.predict(), columns=['active'])\n",
    "\n",
    "#Europe Recovered \n",
    "er_pred = pd.DataFrame(er.predict(), columns=['recovered'])\n",
    "\n",
    "#Asia Active\n",
    "asa_pred = pd.DataFrame(asa.predict(), columns=['active'])\n",
    "\n",
    "#Asia Recovered\n",
    "asr_pred = pd.DataFrame(asr.predict(), columns=['recovered'])\n",
    "\n",
    "#Africa Active\n",
    "afa_pred = pd.DataFrame(afa.predict(), columns=['active'])\n",
    "\n",
    "#Africa Recovered\n",
    "afr_pred = pd.DataFrame(afr.predict(), columns=['recovered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecasting refers to the process of analyzing and elucidating a future state. This process takes the past and the current information into account in a bid to predict facts for future events. This is a quantitative analysis of the data. A forecast is more accurate compared to a prediction. This is because forecast are derived by analyzing a set of past data from past and present trends. The analysis helps in coming up with a model that is scientifically backed and the probability of it being wrong are minimal. Prediction is a statement which explains one possible outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axes = plt.subplots(5, 2, figsize=(14, 14))\n",
    "\n",
    "# Define the date format\n",
    "date_form = DateFormatter(\"%m-%d\")\n",
    "\n",
    "# plotting subplots\n",
    "sns.pointplot(ax=axes[0,0], x=na_pred.index, y='active', data=na_pred, color='b')\n",
    "sns.pointplot(ax=axes[0,0], x=pbc_na.index, y='active', data=pbc_na, color='r')\n",
    "axes[0, 0].set_title('North America Model Comparison', loc='left', pad=15)\n",
    "axes[0, 0].margins(x=0)\n",
    "axes[0, 0].xaxis.set_major_formatter(date_form)\n",
    "axes[0, 0].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[0,1], x=nr_pred.index, y='recovered', data=nr_pred, color='b')\n",
    "sns.pointplot(ax=axes[0,1], x=pbc_nr.index, y='recovered', data=pbc_nr, color='r')\n",
    "axes[0, 1].margins(x=0)\n",
    "axes[0, 1].xaxis.set_major_formatter(date_form)\n",
    "axes[0, 1].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[1,0], x=asa_pred.index, y='active', data=asa_pred, color='b')\n",
    "sns.pointplot(ax=axes[1,0], x=pbc_asa.index, y='active', data=pbc_asa, color='r')\n",
    "axes[1, 0].set_title('Asia Model Comparison', loc='left', pad=15)\n",
    "axes[1, 0].margins(x=0)\n",
    "axes[1, 0].xaxis.set_major_formatter(date_form)\n",
    "axes[1, 0].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[1,1], x=asr_pred.index, y='recovered', data=asr_pred, color='b')\n",
    "sns.pointplot(ax=axes[1,1], x=pbc_asr.index, y='recovered', data=pbc_asr, color='r')\n",
    "axes[1, 1].margins(x=0)\n",
    "axes[1, 1].xaxis.set_major_formatter(date_form)\n",
    "axes[1, 1].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[2,0], x=ea_pred.index, y='active', data=ea_pred, color='b')\n",
    "sns.pointplot(ax=axes[2,0], x=pbc_ea.index, y='active', data=pbc_ea, color='r')\n",
    "axes[2, 0].set_title('Europe Model Comparison', loc='left', pad=15)\n",
    "axes[2, 0].margins(x=0)\n",
    "axes[2, 0].xaxis.set_major_formatter(date_form)\n",
    "axes[2, 0].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[2,1], x=er_pred.index, y='recovered', data=er_pred, color='b')\n",
    "sns.pointplot(ax=axes[2,1], x=pbc_er.index, y='recovered', data=pbc_er, color='r')\n",
    "axes[2, 1].margins(x=0)\n",
    "axes[2, 1].xaxis.set_major_formatter(date_form)\n",
    "axes[2, 1].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[3,0], x=afa_pred.index, y='active', data=afa_pred, color='b')\n",
    "sns.pointplot(ax=axes[3,0], x=pbc_afa.index, y='active', data=pbc_afa, color='r')\n",
    "axes[3, 0].set_title('Africa Model Comparison', loc='left', pad=15)\n",
    "axes[3, 0].margins(x=0)\n",
    "axes[3, 0].xaxis.set_major_formatter(date_form)\n",
    "axes[3, 0].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[3,1], x=afr_pred.index, y='recovered', data=afr_pred, color='b')\n",
    "sns.pointplot(ax=axes[3,1], x=pbc_afr.index, y='recovered', data=pbc_afr, color='r')\n",
    "axes[3, 1].margins(x=0)\n",
    "axes[3, 1].xaxis.set_major_formatter(date_form)\n",
    "axes[3, 1].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[4,0], x=sa_pred.index, y='active', data=sa_pred, color='b')\n",
    "sns.pointplot(ax=axes[4,0], x=pbc_sa.index, y='active', data=pbc_sa, color='r')\n",
    "axes[4, 0].set_title('South America Model Comparison', loc='left', pad=15)\n",
    "axes[4, 0].margins(x=0)\n",
    "axes[4, 0].xaxis.set_major_formatter(date_form)\n",
    "axes[4, 0].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "sns.pointplot(ax=axes[4,1], x=sr_pred.index, y='recovered', data=sr_pred, color='b')\n",
    "sns.pointplot(ax=axes[4,1], x=pbc_sr.index, y='recovered', data=pbc_sr, color='r')\n",
    "axes[4, 1].margins(x=0)\n",
    "axes[4, 1].xaxis.set_major_formatter(date_form)\n",
    "axes[4, 1].xaxis.set_major_locator(mdates.WeekdayLocator(interval=5))\n",
    "\n",
    "\n",
    "# automatically adjust padding horizontally\n",
    "# as well as vertically.\n",
    "plt.tight_layout()\n",
    " \n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Africa, Asia.recovered ARIMA(0,0,0)\n",
    "Asia active, South America Recovered, ARIMA(0,0,1)\n",
    "Europe recovered ARIMA(2,0,0)\n",
    "Europe active, North America, South America Active ARIMA(1,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_future(model, df, s):\n",
    "    forecast = model.forecast(12)\n",
    "    forcast_period = 6\n",
    "    \n",
    "    #Convert dataset to a month daterange\n",
    "    date_range = pd.date_range(df.index[-1],\n",
    "                              periods = forcast_period,\n",
    "                              freq='MS').strftime(\"%Y-%m-%d\").tolist()\n",
    "    \n",
    "    #Convert months to date-time object\n",
    "    future_months = pd.DataFrame(date_range, columns = ['month'])\n",
    "    future_months['month'] = pd.to_datetime(future_months['month'], format='%Y-%m-%d')\n",
    "    future_months.set_index('month', inplace = True)\n",
    "    \n",
    "    #Create prediction column using the forcast\n",
    "    if s == 1:\n",
    "        future_months['active'] = pd.Series(dict(zip(date_range,(forecast[0]))),dtype='object')\n",
    "#         future_months['month'] = pd.to_datetime(future_months['month'], format='%Y-%m-%d').dt.date\n",
    "    if s == 2:\n",
    "        future_months['recovered'] = pd.Series(dict(zip(date_range,(forecast[0]))),dtype='object')\n",
    "\n",
    "    #Append future predictions\n",
    "    past_future = pd.concat([df,future_months])\n",
    "    past_future.index = pd.to_datetime(past_future.index)\n",
    "\n",
    "    return past_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = show_future(afa, pbc_afa, 1)\n",
    "a\n",
    "# sns.lineplot(data=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a variable called forecast_period with the amount of months to forecast, and\n",
    "# create a range of future dates that is the length of the periods you've chosen to forecast\n",
    "forecast_period = 12\n",
    "\n",
    "# Convert that range into a dataframe that includes your predictions\n",
    "date_range = pd.date_range(y_log.index[-1], \n",
    "                           periods = forecast_period,\n",
    "                           freq='MS').strftime(\"%Y-%m-%d\").tolist()\n",
    "print(date_range)\n",
    "# Plot your future predictions\n",
    "future_months = pd.DataFrame(date_range, columns = ['Month'])\n",
    "future_months['Month'] = pd.to_datetime(future_months['Month'])\n",
    "future_months.set_index('Month', inplace = True)\n",
    "\n",
    "future_months['Prediction'] = pd.Series(dict(zip(date_range,(forecast[0]))),dtype='object')\n",
    "\n",
    "# Plot your future predictions\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(y_log)\n",
    "plt.plot(y_log[].append(future_months['Prediction']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbc_na.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
