{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec675b5d-0ba0-42f8-84f4-8686485748a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "986db742-101b-4c91-bd36-863e6697c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid dimensions\n",
    "grid_size = 4\n",
    "\n",
    "# actions: =up, 1=right, 2=down, 3=left\n",
    "actions = [0, 1, 2, 3]\n",
    "\n",
    "# q-table: rows are states (16) columns are actions (4)\n",
    "Q = np.zeros((grid_size * grid_size, len(actions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bbc563-85af-48a6-83a8-09f0338f48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define rewards \n",
    "def get_reward(state):\n",
    "    if state == 15:         #goal\n",
    "        return 10\n",
    "    elif state == 6:        #trap\n",
    "        return -10\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# Convert 20 (row, col) to 1D state index\n",
    "def state_index(row, col):\n",
    "    return row * grid_size + col\n",
    "\n",
    "\n",
    "# move function\n",
    "def take_action(row, col, action):\n",
    "    if action == 0 and row > 0: row -= 1                  #up\n",
    "    elif action == 1 and col < grid_size - 1: col += 1    #right\n",
    "    elif action == 2 and row < grid_size - 1: row += 1    #down\n",
    "    elif action == 3 and col > 0: col -=1                 #left\n",
    "    return row, col    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0c6a5a5-4a6e-4db8-a0d7-e7be491ef238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-learning parameters \n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 0.2\n",
    "\n",
    "# training loop\n",
    "for episode in range(1000):\n",
    "    row, col = 0, 0  # start position\n",
    "\n",
    "    while True:\n",
    "        state = state_index(row, col)\n",
    "\n",
    "        #choose action: explore or exploit\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            action = np.argmax(Q[state])\n",
    "\n",
    "        new_row, new_col = take_action(row, col, action)\n",
    "        new_state = state_index(new_row, new_col)\n",
    "        reward = get_reward(new_state)\n",
    "\n",
    "        # Q-learning update\n",
    "        Q[state, action] += alpha * (reward + gamma * np.max(Q[new_state]) - Q[state, action])\n",
    "\n",
    "        row, col = new_row, new_col\n",
    "\n",
    "        if new_state == 15 or new_state == 6:\n",
    "            break    # episode ends at goal or trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7429a53-6bc7-4f80-ba14-c7ebd11cc849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Q-table:\n",
      "[[ 0.6162463   1.67443561  1.8098      0.60798219]\n",
      " [-0.64199286 -1.51206329  3.1091851  -1.30509134]\n",
      " [-1.12801184 -1.12668414 -1.9        -1.12120766]\n",
      " [-0.58519851 -0.58519851 -0.43306924 -0.76839311]\n",
      " [ 0.62170547  3.10120849  3.122       1.80257894]\n",
      " [ 0.77683267 -6.5132156   4.57999861  0.77853303]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [-0.199      -0.2881      1.49133578 -1.9       ]\n",
      " [ 1.7930089   4.58        4.43413251  3.10015385]\n",
      " [ 3.10776326  6.14156481  6.2         3.0901488 ]\n",
      " [-4.0951      1.66884367  7.99973533  1.42855487]\n",
      " [-0.1667782   0.3961894   7.45813417 -0.1       ]\n",
      " [ 1.37020654  6.19973101  1.49081615  2.07678879]\n",
      " [ 4.57229752  8.          6.17483859  4.56067598]\n",
      " [ 6.15962098 10.          7.98175458  6.17192202]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# display final Q-table \n",
    "print(\"Trained Q-table:\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43041d66-afe4-4ea8-a965-2809c8d5b3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
